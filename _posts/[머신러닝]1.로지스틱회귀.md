---
title: "[머신러닝] 1. 로지스틱 회귀"
date: 2020-03-15 23:54:00 +0800
categories: [연구, 머신러닝]
tags: [머신러닝, 로지스틱 회귀분석, 강의 리뷰]
toc: true
comments: true
use_math: true  	
---



***

> *Intro.*  
> *[머신러닝]이란 사람이 일일이 하기 귀찮거나, 너무 어렵거나, 불가능한 일을*
> *기계=컴퓨터가 할 수 있도록, 컴퓨터가 알아듣는 방식으로 학습시키는 것이다.*     
> *주요한 머신러닝 기법들의 원리를 정리해보자.*

***

![머신러닝](assets/img/머신러닝/pixel-cells)
$$
\def\df#1#2{\dfrac{#1}{#2}}  
   \def\dt{\cdot}
   
   \def\inf{\infty}
   \def\b{\beta}
$$

## **1. 로지스틱 회귀 *Logistic Regression***

흔히 먼저 접하게 되는 선형회귀는 *target* 변수인 $y$가 연속형이지만,
때로는 $y$가 이산형(*countable*)인 경우, 또 그 중에서 0과 1로만 나뉘는 *binary*인 경우가 있을 것이다.

로지스틱 회귀는 $y$가 *binary*인 경우: {좋다, 나쁘다}, {했다, 안했다} 등...
수립할 수 있는 분류 *classification* 모형이다.

일반적인 통계학의 관심 분야처럼 과거의 데이터로 현상을 설명하는 것과 더불어
미래의 데이터에 대해 $y$변수를 정확하게 예측하는 것에 목적이 있다.

> 먼저 과거 데이터라 할 수 있는 training data로 모형을 만들고,
> 미래 데이터인 fresh data로 모형의 성능, 예측 정확도를 평가한다.
>
> 일반적인 선형회귀모형의 결정계수 $R^2$은 training data에 대해 측정한 것이며,
> 미래를 예측하는 정확도는 fresh data로 측정해야 한다. 

***

기존 단순선형회귀모형이 $\hat{y}=b_0+b_1x$ 의 형태였다면,
로지스틱회귀모형은 $\hat{y}=\df{e^{b_0+b_1x}} {1+e^{b_0+b_1x}}$ 의 형태를 취한다. 
이는 그 값이 nonnegative하면서 1을 넘지 않도록 하는, 
부드러운 곡선의 형태로 만드는 sigmoid 함수를 이용해

$\hat{y}$값이 확률의 범위 $[0,1]$을 벗어나지 않게 하고
MLE procedure로 데이터에 가장 적합한 회귀계수를 구할 수 있다.

원래 y값이 0, 1로 딱 나눠졌다면 추정된 값은 0.7, 0.2등 확률로서 표현할 수 있는 것이다. 

### 모형의 해석

기울기의 부호는 curve의 경사 방향을 결정하며, 그 절대적인 크기는 변화율을 의미한다.
만일 기울기가 0이라면 모형은 flat line의 형태가 될 것이다.
일반적인 선형회귀와 다르게 로지스틱 회귀는 $x$값의 크기에 따라서 기울기가 달라지게 된다.
다중회귀모형에서도 $x$변수 별로 이렇게 개별적인 해석이 가능하다는 것이 로지스틱 회귀모형의 장점이다. 

### Cutoff 분류의 경계가 되는 단면



## **Reference**

[“임상시험 단계”에 대한 이해](https://youtu.be/Kemggzyyq6s)   

[이해하는 약리학 20. 임상시험](https://youtu.be/guFrE8VUp4s)

